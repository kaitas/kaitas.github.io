---
layout: post
title: "メタバース時代におけるWebを介した非言語コミュニケーションの社会実装と方法(author's translation)"
date: "2022-01-21 23:52:00"
author: aki
description: メタバース時代におけるWebを介した非言語コミュニケーションの社会実装と方法(author's translation)
preview: https://akihiko.shirai.as/assets/2022/Blog2022.png
---
# メタバース時代におけるWebを介した非言語コミュニケーションの社会実装と方法(author's translation)
# Social Implementation and Methods ofWeb-mediated Nonverbal Communication in the Metaverse Era

## Abstract
<details><summary>English</summary><div>
This paper presents a multi-year research and development project on communication art that can become online and offline tangible shared media in performing art, workshop, and live entertainment events. Such media is important in the coming age of the metaverse, compensating for the opportunity loss caused by the Covid-19 pandemic. We conducted three experimental projects to share the nonverbal experiences of people who are not together in real time and then replay those experiences through three practical art projects of nonverbal communication via the Web in the age of the metaverse. Based on the findings, we predict the future state and social implementation methods of metaverse communication arts.
</div></details>
本論文では、パフォーミングアート、ワークショップ、ライブエンターテイメントイベントにおいて、オンライン・オフラインの有形共有メディアとなりうるコミュニケーションアートに関する複数年にわたる研究開発プロジェクトを紹介する。このようなメディアは、来るべきメタバース時代において、Covid-19のパンデミックによる機会損失を補うものとして重要である。我々は、メタバース時代におけるWebを介した非言語コミュニケーションの実践的アートプロジェクトとして、リアルタイムで一緒にいない人々の非言語体験を共有し、その体験を再生する3つの実験プロジェクトを実施した。その結果をもとに、メタバース・コミュニケーション・アートの今後のあり方と社会実装の方法を予測する。

## CCS Concepts: 
- • Human-centered computing→Scenario-based design;
- • Applied computing→Arts and humanities; Performing arts; Arts and humanities;
- • Social and professional topics → Student assessment; Computing education; Computing education.

## Additional Key Words and Phrases: 

WebXR, WebXR content creation, collaboration in XR, Metaverse
## ACM Reference Format:

> 2022. Social Implementation and Methods of Web-mediated Nonverbal Communication in the Metaverse Era.

## 1 メタバース時代の動機と芸術の文脈
### 1.1 「物理的に、直接」ではなく、「メタバース」へ
来るべきメタヴァース時代［Stephenson and Körber 2002］において、パフォーミングアート、ワークショップ、ライブエンターテイメントイベントとして知られるコミュニケーションアートを、コヴィッド19の機会損失を超えてウェブメディアで展開することに貢献する。物理的に、直接的に」ではなく、Covid-19のパンデミックを超えて、来るべきメタバース時代におけるVR/Web/ビデオストリーミングなどのアートやライブエンターテインメントにおけるオンラインとオフラインの有形共有メディアの可能性について発展的にプロジェクト化する。コミュニケーション・アートの文脈では、人々は、主催者、パフォーマー、そして何かインスピレーションを受ける体験をしたい参加者の役割を担うことになります。一般に観客とカテゴライズされる人々は、参加者として再定義することができる。メタバース時代には、パフォーマーは一人ではなく、ユーザー生成コンテンツ（UGC）［Lastowka and Hunter 2004］やそのジェネレーティブアート［Pang 2015］とともに、オーディエンスのエンゲージメントによって支えられているのだ。実践的な事例と解決策を伴う社会実装は、未来の意味を見出すための合理的な方法である。
<details><summary>English</summary><div>
## 1 MOTIVATION AND ART CONTEXTS IN THE METAVERSE ERA
### 1.1 Instead of “in a physical, in person,” into a metaverse
We contribute to developing communication arts, known as performing art, workshop, and live entertainment events in web media in the coming age of the metaverse [Stephenson and Körber 2002], beyond the Covid-19 opportunity loss. Instead of “in a physical, in person,” developmental project on the potential of online and offline tangible shared media in art and live entertainment such as VR/Web/video streaming in the coming age of the metaverse, beyond the Covid-19 pandemic. In a communication art context, people will play the role of organizers, performers, and participants who want to experience something inspired. The people who are generally categorized as the audience can be redefined as participants. In the metaverse era, the performers are not alone; they are supported by audiences’ engagements together with user generated contents (UGCs) [Lastowka and Hunter 2004] and their generative arts [Pang 2015]. Social implementations with practical cases and solutions are reasonable ways to find future meanings.
</div></details>

### 1.2 オンライン言語コミュニケーションの問題点
Covid-19[Hildebrandt 2020; Warnecke 2020]の拡散を避けるため、アートやエンターテインメントのイベントにおいて遠隔会議やビデオストリーミングサービス（ウェブメディアと呼ばれる）が広く使われるようになりました。しかし，コミュニケーション・アートの文脈では，パフォーマーと観客のインタラクションは，テキストコメントによる質疑応答，エモートの送信，休憩室での限られた人数との会話に限られる．このようなコミュニケーションの非対称性は、ツールやプラットフォームの制限やデザインに起因する。テキストコメント（YouTube Super Chatのような商業的な有料契約を含む）やボーカルコミュニケーションなどの言語的なインタラクションは、理論的には有効です。しかし、実際には、テキストコメントは、それが書かれている言語を読むことができる人々にのみ有効であり、双方向の音声コミュニケーションは、少人数でのコミュニケーションに限られます。テキストメッセージは大規模なイベントには有効ですが、問題もあります。これらは他の聴衆に共感を生むことが期待される一方で、メインコンテンツから文脈的に離れているため、攻撃的な印象を与える可能性があります[Gibson 2020; Kusumawardani and Trijayanto 2020; Lingam and Aripin 2017]。さらに、文章を書いたり読んだりすることは、観客の注意をメイン・コンテンツから引き離すことになる。ファインアートに限らず、実際のアートイベントでは、大勢の観客、拍手、歓声、声の反応、驚きといった感情や環境の文脈が、演者や観客全体に自然に共有されるが、そうした感情を明示的なテキストや文章で表現することは難しい。現代のメディアアートは、観客やパフォーマーを巻き込み、言語感覚に限定されない意味を持つものであるべきです。

<details><summary>English</summary><div>
### 1.2 Issues of online verbal communication
Remote conferencing and video streaming services (as referred to web media) have become widely used in art and entertainment events to avoid spreading Covid-19[Hildebrandt 2020; Warnecke 2020]. However, in the context of communication art, the interaction between the performers and the audience is limited to question-and-answer via text comments, sending emotes, and conversations with a limited number of people in breakout rooms. This asymmetry of communication is due to the limitations and design of the tool or platform. Linguistic interactions, such as text comments (including commercially-paid engagements such as YouTube Super Chat) and vocal communication, work in theory. Howerver, in practice, text comments are only effective for people who can read the language in which they are written and bidirectional vocal communication is limited in a small group. Text messaging is useful for massive event but it has also a problem: while these are expected to create empathy in the rest of the audience, their contextual separation from the main content can lead to aggressive impressions[Gibson 2020; Kusumawardani and Trijayanto 2020; Lingam and Aripin 2017]. Furthermore, writing and reading texts draw audience attention away from the main content. In an actual art event, and this is not limited to fine art, the emotional and environmental context—a large audience, applause, cheers, vocal response, and amazement—are naturally shared to the performers and throughout the audience, but it is difficult to express such feelings in explicit text or writing. In contemporary, media art should be inclusive of audiences and performers, and the meanings should not be limited to the linguistic senses.
</div></details>

### 1.3 ノンバーバルコミュニケーションの重要性
他の観客の存在、感情、エネルギー、拍手、歓声など、現実のイベントでは当たり前の非言語情報が多く欠落しています。
先行研究において、非言語情報の重要性が言及されていることを考えると、これは重要な問題である。
ライブ音楽の文脈では，Peacockeらが観客の存在がライブ音楽体験に重要であることを指摘している[Peacocke and Fine 2021]．
Scholtensは，自閉症スペクトラムのより深い影響を受けている端の生徒の共同注意コミュニケーションスキルの発達を支援するための音楽レパートリーの選択について，教育的，社会的，科学的根拠を報告している[Scholtens 2019]。
アートインクルージョン、自閉症スペクトラム障害、共同注意の育成、特別な学習者のためのレパートリーという文脈だけに限定されるべきではないだろう。非言語コミュニケーションにおける芸術的表現方法の開発は、コンピュータアートの歴史における現在の音楽レパートリーの開発以上の意味を持つだろう[Rebelo 2006]。


<details><summary>English</summary><div>
### 1.3 Importance of nonverbal communication
Much nonverbal information, such as the presence, emotions, and energy of other audience members, applause, and cheers, which are commonplace in real-world events, is missing in online environments.
This is an important problem considering that the importance of nonverbal information is mentioned in previous studies. 
In the context of live music, Peacocke et al. point out that the presence of the audience is important to the live music experience[Peacocke and Fine 2021]. 
Scholtens reported educational, social, and scientific rationales for selecting musical repertoire to support the development of joint attention communication skills for students on the more profoundly affected end of the autism spectrum[Scholtens 2019]. 
It should not be limited only in the context of arts inclusion, autism spectrum disorder, fostering joint attention, repertoire for special learners. Development of artistic expression methods in nonverbal communication will have meanings more than developing current musical repertoires in computer arts history[Rebelo 2006].
</div></details>

## 2 "パフォーマー": 音楽演奏者のためのタンジブル・インタラクティビティ

### 2.1 コンセプトと課題

本プロジェクトは、オンラインライブにおいて、観客が一体感を感じ、演奏者が観客の存在を感じられるようにすることを目的としています。音楽関係者へのヒアリングから、（1）適切なタイミングでの拍手の必要性、（2）観客が他の観客と感動を共有したい、（3）主催者がインタラクティブ性の効果を測定したい、などの課題が見えてきました。

### 2.2 芸術の現状：演者と観客のための感情コミュニケーションアートツール
これらの課題を解決するために、図1に示す「パフォーマー」アートを開発しました。主な特徴は以下の通りである。(1)絵文字による感情表現。視聴者は、絵文字をタップするだけで、現在の感情や気持ちをパフォーマーに表現することができます。タップ操作は簡単で、視聴の妨げにならず、視聴者はライブを盛り上げることができます。(2) 映像・音・触覚で演者に臨場感を提示 観客が送った絵文字を、プロジェクションマッピングや効果音、振動などで演者が直感的に体感することで、公演中にも観客の存在を感じることができる。
(3) 遅延を超えた協調技術「Future-cue-card」。Future-cue-cardは、出演者と視聴者のオンラインライブのやりとりの遅延をなくします。公演会場のディレクターは、観客に「公演終了！」などのメッセージを即座に送ることができる。図2のように、視聴者に「公演終了！拍手をお願いします」というメッセージを瞬時に送り、公演終了時に視聴者が拍手の絵文字を遅延なく送れるようにする。

<details><summary>English</summary><div>
## 2 “PERFORMER”: TANGIBLE INTERACTIVITY FOR MUSIC PERFORMERS
### 2.1 Concept and Issues
This project aims to enable the audience to feel a sense of unity and the performers to feel the audience’s presence in live online performances. From interviews with people involved in the field of music, we found issues such as (1) the need for applause at appropriate times, (2) the audience wanting to share their excitement with other audience members, and (3) the organizers wanting to measure the effectiveness of the interactivity.
### 2.2 State of arts: emotional communications art tools for the performer and audience
To solve these issues, we developed the “Performer” art shown in Figure 1. The main features are as follows: (1) Emotional expression by emoji. Viewers can express their current emotions and feelings to the performers by simply tapping on the emojis. Tapping is easy to do and does not interfere with the viewing experience, and the audience can liven up the live performance. (2) Presenting the audience’s presence to performers through images, sounds, and tactile sensations. Emojis sent by the audience can be intuitively experienced by the performers through projection mapping, sound effects, and vibrations, allowing them to feel the audience’s presence even during the performance.
(3) “Future-cue-card”—cooperative technology beyond delay. A Future-cue-card eliminates delays in live online interactions between performers and viewers. The director at the performing venue can send an instant message to the audience such as, "Performance is over! Please give us applause" to the viewers as shown in Figure 2 so that they can send applause emojis with no delay at the end of the performance.
</div></details>

#### Fig. 1. System configuration of “Performer”.

### 2.3 評価 観客と演者からのフィードバック
ライブデモ実験の3日間のうち、参加者が最も多かった3日目（n=31）を中心に紹介する。観客が送った絵文字は、図3の4種類である。
観客が絵文字をタップした回数は71,323回で、観客1人が1分間に平均20個の絵文字を送信したことになる。
一方、YouTubeチャンネルには242件のコメントが残されています（視聴者はコメントを並列に入れることができます）。
この結果から、絵文字による応援は、YouTubeのコメントによる応援よりも視聴者にとって容易であり、パフォーマンスを盛り上げるのに役立っていることがわかります。図3に示すように、観客は公演中に拍手なしの絵文字を送り、公演が終わると拍手絵文字を送る傾向がありました。
これは、観客が絵文字を実際のツッコミや拍手の代わりに使っていることを示しています。
公演終了後、一部の観客にアンケートを実施した。年齢の内訳は以下の通りであった。20代: 30代: 40代: 50代: 60代：不明＝1、3、8、6、3、1、男性、女性＝11、11。パフォーマー」アートは、22人中19人が「楽しんで使っている」と回答し、性別や年齢を問わず、観客にマッチしていることが確認できた。さらに、半数が「パフォーマーとの一体感を感じた」と回答しており、約3分の1が次のように回答しています。"他の観客との一体感を感じた" "一緒にライブを作っている感じがした" "演奏者に感情が伝わった "などの回答がありました。公演終了後、公演中の触覚の印象について、出演者にインタビューを行いました。すると、全員が「演奏中でも触感を感じることができ、演奏の妨げにならない」と回答。
さらに、触覚によって観客の歓声を感じることができ、観客の存在を感じることができ、演奏者にとっては嬉しいことであった。このように、アートと触覚は観客の鑑賞体験を向上させ、演者は観客の存在を感じることができたと結論付けています。

<details><summary>English</summary><div>
### 2.3 Evaluation: Feedback from the audiences and performers
Of the three days of the live demonstration experiment, we will focus on the third day, with the most participants (n = 31). The four types of emojis sent by the audience are shown in Figure 3. 
The total number of times the audience tapped the emojis was 71,323, which means one audience member sent 20 emojis per minute on average.
In contrast, 242 comments were left on the YouTube channel (the audience can put comments parallelly).
This result shows that cheering with emojis is easier for viewers than cheering by YouTube comment and helps make the performance more lively. As shown in Figure 3, audience members tended to send emojis without claps during the performance and clap emojis when the performance ended. 
This indicates that the audience uses emojis to substitute for real-life tweets and applause.
Some audience members completed a questionnaire after the performance. The age breakdown was as follows: 20s: 30s: 40s: 50s: 60s: unknown = 1, 3, 8, 6, 3, 1, male, female = 11, 11. Nineteen of 22 respondents answered that they enjoyed using the “Performer” art, confirming that it suited the audience regardless of gender or age. Additionally, half answered, “I felt a sense of unity with the performers”, about a third of them answered as follows: “I felt a sense of unity with other audience members,” “I felt like we were making a live concert together,” and “I could convey my emotions to the performers.” After the performances, we interviewed the performers about their impression of tactile sensation during the performance. They all answered that they could feel the tactile sensation even during the performance, and it did not interfere with the performance.
Furthermore, the tactile sensation allowed the performers to feel the audience cheering, making the performers happy to feel the presence of viewers. We conclude that this art and tactile sensation improved the audience’s viewing experience and made the performers feel the audience’s presence.
</div></details>


#### Fig. 2. User interface of “Performer.” The text at the top is the message from the director at the venue using Future-cue-card.

#### Fig. 3. Timeline chart of recorded tap info.

## 3 "メタ・トラベル": Webを介した世界旅行のワークショップ
### 3.1 コンセプト 3.1 コンセプト：子どもたちを海外に連れ出し、海外の環境に触れさせる
本プロジェクトは、海外旅行の経験がない子どもたちが、仲間と一緒に海外旅行を体験し、歩き、ネットで写真を撮ることで、海外の文化に触れ、訪れた土地に興味を持つことができるかを検証することを目的としています。

### 3.2 実装：集合観光写真を撮影できるWebXRメタバース
Meta-travel（匿名化）は、ビデオ会議ツールを用いて小中学生が遠隔で利用することを想定した仮想旅行工房システムです。子どもたちが簡単に観光地に没頭できるように、汎用的なWebブラウザ上でMaps JavaScript APIを使って動作し、URLをクリックすることで参加できるようになっています。
図 4 は「探索モード」の画面であり，プレイヤーはその場 所を自由に移動し，アイテムを探したり，カメラボタンを 押して写真を撮ったりできる（図 4（3））．撮影時には、プレイヤーや他のプレイヤーのアバター画像（図4（10））、背景画像、画角の情報がURL形式で内部に保存される。Meta-travelのシステム構成は図5に示す通りである。

#### 図4. 左：Meta-travelの探索モードインタフェース．
(1) プレイヤーの名前とアバター．
(2) コンパスボタン．プレイヤーは(8)アバターコンパスを表示することができる．
(3) カメラボタン．このボタンを押すと、写真を撮ることができます。
(4) アイテム収納。獲得したアイテムはここに表示されます。
(5) 別の場所にいる他のプレイヤーのアバター。このアバターの位置は、プレイヤーの位置が反映されています。
(6) メッセージ表示。ミッションが表示されます。
(7) 同じ場所にたどり着くと手に入るアイテム。
(8) アバターコンパス。赤い三角形はアバターの進行方向を示し、下部の数字はその方向にコンパスで表示されているアバターとの距離を示しています。
(9) アイテムの方角と距離を示すアイテムコンパス。
(10) 同じ場所にいる他のプレイヤーのアバター。このアバターは、右図のように撮影した写真に表示されます。
(11) ジャンプボタン。プレイヤーはすぐに特定の場所にワープすることができる。
右図 この状態で撮影した写真の例。プレイヤーのアバターと他のプレイヤーが写っている。
同じ場所です。アバターは写真を撮るたびにフォトジェニックなポーズをとってくれます。

#### 図5. Meta-travel art のシステム構成．
矢印の色は伝達される情報の種類を表している。システム上で動くたびに、位置情報（緑の矢印）が伝達される。
XRの写真情報（ピンクの矢印）は、プレイヤーが写真ボタンを押したときに伝達される。アイテム情報（黄色の矢印）は、プレイヤーがアイテムを取得したとき、またはアイテム収納庫のアイテムアイコンをクリックしたときに通知されます。コマンド情報（青矢印）は、旅の進行を管理するガイドがコンソールページを操作したときに通知されます。

### 3.3 物語のデザイン メタトラベルのワークショップと体験
子ども向けの旅行ワークショップは、90分のワークショップ形式で4回開催された。
参加者は11歳から14歳までの計24名で、各回の定員は9名であった。
参加者はそれぞれ、旅のシナリオ（タイ、イタリア、フランス）のうち1つだけに参加しました。
各シナリオの冒頭で、図 4 のような機能を説明するチュートリアルを行った。その後，参加者は制限時間内に訪れた場所を自由に探索した．
以下に、各シナリオの特徴を簡単に説明する。タイシナリオは、"タイのバンコクにあるピンクの巨大な象の像に会いに行こう "というタイトルであった。
参加者は空港や街中、市場、寺院などを訪れ、「両替所を探す」「宿泊先を探す」「お土産を買う」など、実際の旅行では欠かせないミッションを実行した。
イタリアシナリオでは、「魅惑のベネチア～ベネチアの宮殿と水の迷宮を探検せよ～」と題し、ベネチアの川や宮殿を訪れ、街並みや建築様式を体感しました。最後に、地球温暖化によるベネチアの水位上昇をテーマにした映画を鑑賞し、クイズに答えていただきました。
フランスのシナリオでは、「天空の城ラピュタの旅! フランスで列車の旅" フランスの高速列車TGVの停車駅で下車し、目的地のモンサンミッシェルでフォトジェニックなスポットをたくさん訪れるというシナリオです。

(訳注：ラピュタどこからでてきた・・・笑)

### 3.4 評価 参加者の行動による客観的な評価
ワークショップ期間中に参加者が行った「移動回数」（マウスで背景領域をクリックした回数に相当する総移動回数から、シナリオごとに提示されたミッションを達成するために必要な最小移動回数を引いた値で取得）と「写真撮影枚数」の関係を図6に示す．全体の移動回数とXR写真の撮影枚数の平均値から、図6のように、参加者をHH、HL、LH、LLの4つのグループに分類した。また、各シナリオの特徴を図示している。タイのシナリオでは、参加者のほとんどがLLグループに分類され、フォトジェニックな場所がなく、探索の魅力に欠けるシナリオであることが示された。そのため、このシナリオでは、より魅力的な場所を追加する必要がある。イタリアのシナリオでは、参加者は主にHLグループに分類され、探索するのに魅力的で、迷いやすいと回答しています。
<!--フランスシナリオでは、参加者は主にLHグループに分類され、シナリオにフォトジェニックな場所が多く、参加者の写真撮影の動機付けになることが示された。-->
フランスシナリオの結果から、参加者はほとんどLHグループに分類される。フォトジェニックな場所が多く、参加者のモチベーションが高かったことがうかがえる。

<details><summary>English</summary><div>
## 3 “META-TRAVEL”: WEB MEDIATEDWORKSHOP OFWORLD TRAVEL
### 3.1 Concept: Bring children to abroad to exposed foreign environment
This project aims to evaluate whether children who have never traveled abroad can be exposed to foreign cultures and develop an interest in the places they visit by having them experience traveling abroad with their peers, walking around, and taking pictures online.

### 3.2 Implementation:WebXR Metaverse which able to take a group touring photo
Meta-travel (anonymization), a virtual travel workshop system, is intended to be used remotely by elementary and junior high school children using video conferencing tools. To ease to immerse children to the sights, it run with Maps JavaScript API on a general-purpose web browser and allow participation by clicking URLs.
Figure 4 shows the screen of the "exploration mode," where the player can freely move around the location, search for items, and take pictures by pressing the camera button (Figure 4 (3)). When taking a picture, the following information is saved internally in URL format: the avatar images of the player and other players (Figure 4(10)), background image, and angle of view. The system configuration of Meta-travel is shown in Figure 5.

#### Fig. 4. Left: Meta-travel explore mode interface. 
(1) Player name and avatar. 
(2) Compass button. The player can display the (8) avatar compass. 
(3) Camera button. The player can take a photo by pressing this button.
(4) Item storage. Acquired items appear here. (5) An avatar of another player in a different location. The locations of these avatars reflect the position of the players. (6) Message display. Missions appear here. (7) An item that can be acquired by reaching the same location.
(8) Avatar compass. The red triangles indicate the avatar’s direction of travel, and the numbers at the bottom indicate the distance between the avatar and the avatar shown with the compass in that direction. 
(9) Item compass that indicates the direction of and distance to the item. (10) An avatar of another player in the same location. This avatar appears in the photo taken, as shown in the right figure. (11) Jump button. The player can warp to a certain place immediately. 
Right: Examples of a photo taken in this condition. The photo shows the player avatar and another player in
the same location. The avatars make a photogenic pose on each photo taken.


#### Fig. 5. System configuration of Meta-travel art. 
The arrow colors indicate the type of information to be communicated. Every movement on the system communicates locational info (green arrow). 
XR photo info (pink arrow) is communicated when the player presses the photo button. Item info (yellow arrow) is communicated when the player acquires an item or clicks an item icon in the item storage. Command info (blue arrow) is communicated when the guide, who manages the travel progress, manages the console page.

### 3.3 Narrative Design: Meta-travel workshop and experience
Travel workshops for children were held four times in the form of 90-minute workshops. 
The total number of participants was 24, ranging from 11 to 14 years old, with a maximum of nine participants in each session. 
Each participant participated in only one of the travel scenarios (Thailand, Italy, or France). At the beginning of every scenario, we held a tutorial session explaining the features shown in Figure 4. After that, participants were free to explore the visited places within a given time limit. The features of each scenario are briefly described below. For the Thai scenario, the title was “Let’s meet the giant statue of a pink elephant in Bangkok, Thailand.” The participants visited the airport, streets, markets, and temples and executed missions such as "finding a money exchange place," "finding a place to stay," and "buying souvenirs," which are essential activities in actual travel. 
For the Italian scenario, the title was “Fascinating Venice — Explore Venetian Palace and Water Maze” The participants visited the rivers and palaces in Venice to experience the city and its architectural style. At the end, participants watched a movie about the rising water level in Venice due to global warming, followed by a quiz. For the French scenario, the title was “Trip to the Castle in the Sky! Train Trip in France.” The scenario consists of getting off at a stop of the TGV, a high-speed train in France, and visiting many photogenic spots at the destination, Mont Saint-Michel.

### 3.4 Evaluation: Objective evaluation through the behavior of the participants
The relationship between the “number of movements” (acquired by the total number of movements, corresponding to the number of clicking the background area with a mouse, minus the minimum number of moves required to accomplish the mission presented for each scenario) and “number of photos taken” by the participants during the workshop is shown in Figure 6. Based on the mean values of the overall number of movements and number of XR photos taken, we classified the participants into four groups: HH, HL, LH, and LL, as shown in Figure 6. It is also illustrating the characteristics of each scenario. For the Thailand scenario, the participants were mostly classified into the LL group, indicating that the scenario lacks photogenic places and is unattractive to explore. Thus, this scenario needs to add more attractive places to visit. For the Italy scenario, the participants were mainly classified into the HL group, indicating that the scenario was attractive to explore and easy to get lost in. 
<!--For the France scenario, the participants are mostly classified into the LH group, indicating that the scenario has a lot of photogenic places and motivates the participants to take photos.-->
From the result of the France scenario, the participants are mostly classified into the LH group. It tells the scenario has a lot of photogenic places and participants were well motivated.
</div></details>

## 4 「メタ・クリエーター」。ユーザが作成するコンテンツを作成するためのツール
### 4.1 コンセプト プレゼンスと行動を用いた非言語的なユーザー生成のメタナラティブ体験
本プロジェクトは、OUR-PROJECTの機能的・社会的実装（匿名化）から生まれたユーザーの経験をUGC（ユーザー生成コンテンツ）として作成することを目的とする。UGCは、空間と時間を超えてユーザーの経験を共有する非言語メタナラティブ・コンテンツである。

### 4.2 実装 地球規模の地球規模での方向感覚
"Directional Sense"は、複数の触覚アクチュエータを用いて、空間的な距離や位置関係を表現するアルゴリズムである。久米ら[Kume 1998]は、このような複数のアクチュエータを用いた触覚表現を開発した。
しかし、このツールをUGCとして利用するには、開発者用の特別なツール、モーションキャプチャのような環境、そして少なくとも2組のデバイスが必要である。
本研究では、空間内の他のユーザの座標、軌跡、絵文字に「方向感覚」を付与し、メタバースでは見えない非言語的なユーザ生成メタナラティブコンテンツを自由に生成・共有することを可能にする。
アルゴリズムはシンプルでありながら、小さな空間から地球上のような大きな空間まで表現することができる。

#### 図7. 方向感覚の説明

### 4.3 実装 4.3 実装：「タイムシフト」、時間をまたぐ非同期体験コンテンツ生成
"Timeshift "は時間を超越したUGC機能です。
ビデオ視聴可能なコンテンツなど、過去のオンラインイベントとイベント開始からの経過時間を記録し、そのオンラインイベントに対するクラウド接続側のユーザーの反応を記録し、タイムシフトとして再生・共有するものである。
また、当技術は、位置情報や音声などのロケーションベースのコンテンツも扱うことができます。
拍手や歓声、絵文字などの小さな信号を大量に記録・再生することで、同じイベントを多くの視聴者と同時に見ているような感覚を再現することができる。
これにより、ライブと録画の不一致を解消し、居住地が異なる場合の時差を解消する効果がある。視聴者にとっては、ライブイベントにおけるTwitterのような非同期コミュニケーションとして認識することができます。"Timeshift "は、"Performer "が書いたエモーションなどの非言語情報を非同期的に共有することができます。ユーザーは、動画にタップ情報を付加することで、あらゆる動画に付加価値を与えることができます。これにより、誰でも簡単に動画を面白くするための後処理を行うことができます。

#### 図8. "タイムシフト "のコンセプト

### 4.4 実施と評価 ：メタトラベルのためのノンバーバルUGCツール「シナリオメーカー」
第三者が簡単にメタトラベル用のシナリオを作成できるように、図4（6）のGoogle MapストリートビューのURL（プレイヤー遷移、目的地、視野角、経由地、仮想アイテム配置を指定）と表示したいテキストを入力すると、シナリオ実装用のJSONファイルを自動生成できるGoogle Sheetを開発しました。このツールを用いて、タイと日本の大学生がグループごとに、タイと日本の文化を紹介するオリジナルの旅行シナリオを作成しました。その結果、日本とタイの都市部と自然部の違いに着目したシナリオ、タイの寺院に焦点を当てたシナリオ、観光地を巡るシナリオなど、グループごとに異なる特色が現れた。小型の触覚デバイスであるHAPTIC-DEVICE-NAME（匿名化）は、物理的な移動で共有でき、どちらのグループでもうまく機能した。このように、各人のビジョンを旅行シナリオという形で直感的に表現することができる。このツールは、メタバース時代の新しいUGCとして発展していくことが期待される。

<details><summary>English</summary><div>
## 4 “META-CREATOR”: TOOLS FOR CREATING USER GENERATED CONTENTS
### 4.1 Concept: Nonverbal user-generated metanarrative experience using presence and behavior
This project aims to help users create user-generated content (UGC) of their experiences that emerged from the functionality and social implementation of OUR-PROJECTs (anonymization) The UGC is nonverbal metanarrative content that shares the users’ experience beyond space and time.

### 4.2 Implementation: Directional Sense in the global earth scale.
“Directional Sense” is an algorithm that uses multiple tactile actuators to represent spatial distance and positional relationships. Kume et al. [Kume 1998] developed such tactile representations using multiple actuators. However, using this tool as a UGC requires special tools for developers, an environment like motion capture, and at least two sets of devices. We assign “Directional Sense” to the coordinates, trajectories, and emojis of other users in the space, allowing them to freely generate and share nonverbal user-generated metanarrative contents which is not visible in the metaverse. The algorithm is simple yet can represent anything from a small space to a large space such as the global earth.

#### Fig. 7. Description of directional sense

### 4.3 Implementation: “Timeshift”, Asynchronous experience content generation across time
“Timeshift” is a UGC feature that transcends time. It records past online events, such as videoviewable content and the time elapsed since the start of the event, and records the reactions of users on the cloud-connected side to the online event, which is then played back and shared as a time-shift. 
The art can also handle location-based content such as location and audio. 
By recording and playing back a large number of small signals such as applause, cheers, and emojis, it can reproduce the feeling of watching the same event simultaneously with many other viewers. 
This has the effect of resolving the discord between live and recorded events and resolving the time difference between different places of residence. For the audience, it can be recognized as an asynchronous communication similar to Twitter for live events. “Timeshift” can asynchronously share nonverbal information such as emotes written by “Performer.” Users can add value to any video by adding tap information to the video. This makes it easy for anyone to post-process a video to make it more interesting.

#### Fig. 8. “Timeshift” concept

### 4.4 Implementation and Evaluation: “Scenario Maker”, nonverbal UGC tool for Meta-travel
To enable third parties to easily create scenarios for Meta-travel, we developed a Google Sheet that can automatically generate a JSON file for scenario implementation by entering the URL of Google Map Street View (specifying the player transition, destination, view angle, way point and virtual item placement) and the text to be displayed in Figure 4 (6). Using this tool, each group of Thai and Japanese universities students created their original travel scenario to introduce the cultures of Thailand and Japan. As a result, different characteristics appeared in each group, such as a scenario focusing on the differences between urban and natural areas in Japan and Thailand, a scenario concentrating on Thai temples, and a scenario visiting touristic sites. HAPTIC-DEVICE-NAME (anonymization), a small haptic device, could be shared by physical transportation, and it worked well in both groups. In this way, each person’s vision can be intuitively expressed in the form of a travel scenario. The tool is expected to develop as a new UGC in the metaverse era.

</div></details>

## 5 結論と未来予想図：タンジブル・シェアード・エンタテインメントとメタヴァース
本稿では、来るべきメタバース時代のアートやライブエンターテインメントにおけるオンライン・オフラインの有形の共有メディアの可能性について、コヴィッド19関連の機会損失を超えて、複数年にわたる研究開発プロジェクト「OUR-PROJECTs」を総括したものである。本稿では、時間や場所を超えた触覚的な対面共有体験を可能にするOUR-PROJECTsの代表的なプロジェクトや、音楽演奏家によるライブ演奏の触覚的インタラクティビティについて議論した。
また、子供や大学生がメタバースで視覚化・触覚化できるリアルタイム体験も実現した。これらの体験は、YouTubeなどを用いた実験イベントやライブイベントなどで共有・発信してきました。

ここでは、これらの作品の制作や社会実装の課題について、予測を行います。
バーチャルフレンドとインタラクティビティ、旅行、ライブイベントの観戦と拍手・歓声。
かつてはライブ会場でしかできなかったこのような活動が、メタバースでは場所や時間を超えて実現できるようになりました。一人の視聴者の個人的な体験が、イベントに参加している他の人の体験と融合することができるのです。このような体験は有機的なものではないかもしれないし、人々は摩擦や議論をすることもあるかもしれない。しかし、それはテクノロジーの恩恵と公共への理由によって、より自然なものになるはずです。私たちのプロジェクトや社会実装を通じて、いくつかの自治体から、ユニバーサルデザインを超えたソーシャルインクルージョンのための手法を美術館や劇場に適用してほしいという要望がありました。例えば、音声障害者のための音楽ワークショップを開催したり、Peter 2.0 [SCOTT-MORGAN 2021]のように、障害を持つ高齢者や家族・友人と写真を撮ったり、(実質的な;virtually)海外旅行したりすることができます。
また、遠隔地にある2つの国立大学間で、アートとテクノロジーのワークショップを実施しました。
<!--このように，Web を媒介とした非言語コミュニケーションは，Zoom などの音声限定通信サービスや特殊なデバイスに頼らず，WebXR とオンラインイベントだけで自宅から実現できることが大きな特徴である．-->
このWebを介した非言語コミュニケーションは、Zoomなどの音声限定通信サービスや特殊なデバイスに限らず、WebXRやオンラインイベントを使って自宅から実現できることが大きな特徴です。

参加者である大学生も、このコンテンツアートを多言語・多文化で利用し、簡単なツールでコンテンツを生成していました。Covid-19のパンデミックのような状況では、本稿で紹介したような多言語だが物理的に離れた、非言語的な、ウェブを介したコミュニケーションが、仮想存在のメタバース時代には一般的になるであろう。さらに、HMDなどの高貴なARデバイスを装着している人だけでなく、携帯電話や音楽教室などでも利用できるようになり、非言語UGCはより一般化するはずである。タンジブルメディアや触覚体験の研究開発に携わる者にとって、Covid-19はメタバース時代への大きなブレークと飛躍の機会であった。本稿では、こうした背景のもと、個々のプロジェクトの知見や意味を再構築し、CG／インタラクティブなメタバースとライブイベントの融合を考えるアートプロジェクトとしての意味を言語化することに努めた。このプロジェクトが、一過性の商業・消費コンテンツではなく、人類の歴史において「誰かと一緒にどこかに行き、表現し、共有する」という行為の意味を考えるきっかけになればと思います。

[脚注】本投稿では、関連する学術的な貢献、アーティスト名、会場名などを一部匿名化し、引用していない。

<details><summary>English</summary><div>
## 5 CONCLUSION AND A PREDICTION OF THE FUTURE: TANGIBLE SHARED ENTERTAINMENT AND THE METAVERSE
This paper summarizes OUR-PROJECTs, a multi-year research and development project on the potential of online and offline tangible shared media in art and live entertainment in the coming age of the metaverse era, beyond the Covid-19 related opportunity loss. In this paper, we discussed representative projects of OUR-PROJECTs that enable tactile in-person shared experiences that transcend time and place and the haptic interactivity of live performances by music performers.
We have also created real-time experiences that enable children and university students to visualize and tactilize their experiences in the metaverse. We have shared and disseminated these experiences at experimental and live events using YouTube and other media.

Here, we offer predictions about the creation and challenges of these works and social implementations:
Virtual friends and interactivity, traveling, watching live events and clapping and cheering. 
This kind of activity, which once could only be done in person at a live event, can now be achieved beyond place and time in the metaverse. The individual experience of one viewer can be merged with the experience of other people participating in the event. This kind of experience may not be organic and people may have some frictions and discussions. But it will become more natural with the benefit of technologies and reasons into the public. Through our project and social implementation, some local government asked us to apply methods to art museum and theaters for social inclusion beyond universal design. For example, we can organize a music workshop for audio disable people, we can take a picture or travel abroad with an elderly or family and/or friend who has disabled like Peter 2.0 virtually [SCOTT-MORGAN 2021]. 
We have also executed art and technology workshops between two national universities in remote. 
<!--Significantly, this web-mediated nonverbal communication can be realized from home using only WebXR and online events without relying on vocal limited telecommunication services such as Zoom or special devices. -->
Significantly, this web-mediated nonverbal communication can be realized from home using WebXR and online events not only limited on vocal limited telecommunication services such as Zoom or special devices.
Participants, University students also used this content art in multiple languages and cultures to generate content with simple tools. In a situation like the Covid-19 pandemic, a multi-lingual but physically separated, nonverbal, web-mediated communication as described in this paper will be common in the era of Metaverse for virtual beings. Furthermore, nonverbal UGCs should become more common, as they become more accessible to people not only wearing HMDs or other noble AR devices but also mobile phone or music classroom. For those involved in the research and development of tangible media and tactile experiences, Covid-19 was an opportunity to make a significant break and a leap into the metaverse era. This paper has tried to reconstruct the findings and meanings of these individual projects against this backdrop and verbalizes their meaning as art projects that consider the integration of CG/interactive metaverse and live events. We hope that this project will provide an opportunity to think about the meaning of the act of "going somewhere with someone, expressing and sharing" in the history of humankind, rather than transient commercial and consumer content.

[Footnote] Some relevant academic contributions, artist names, and venues have been kept anonymous and/or not cited in this submitted paper.

</div></details>